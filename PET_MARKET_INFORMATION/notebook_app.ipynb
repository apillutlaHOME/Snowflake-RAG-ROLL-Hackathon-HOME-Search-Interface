{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1555c09c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import python packages\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "   \n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "import streamlit as st # Import python packages\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "from snowflake.cortex import Complete\n",
    "from snowflake.core import Root\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pd.set_option(\"max_colwidth\",None)\n",
    "\n",
    "### Default Values\n",
    "NUM_CHUNKS = 3 # Num-chunks provided as context. Play with this to check how it affects your accuracy\n",
    "slide_window = 7 # how many last conversations to remember. This is the slide window.\n",
    "\n",
    "# service parameters\n",
    "CORTEX_SEARCH_DATABASE = \"PET_MARKET_ECONOMICS_DATABASE_SEARCH\"\n",
    "CORTEX_SEARCH_SCHEMA = \"PUBLIC\"\n",
    "CORTEX_SEARCH_SERVICE = \"PET_MARKET_ECONOMICS_SEARCH\"\n",
    "######\n",
    "######\n",
    "\n",
    "# columns to query in the service\n",
    "COLUMNS = [\n",
    "    \"chunk\",\n",
    "    \"relative_path\",\n",
    "    \"category\"\n",
    "]\n",
    "\n",
    "session = get_active_session()\n",
    "root = Root(session)                         \n",
    "\n",
    "svc = root.databases[CORTEX_SEARCH_DATABASE].schemas[CORTEX_SEARCH_SCHEMA].cortex_search_services[CORTEX_SEARCH_SERVICE]\n",
    "   \n",
    "### Functions\n",
    "     \n",
    "def config_options():\n",
    "\n",
    "    st.sidebar.selectbox('Select your model:',(\n",
    "                                    'mixtral-8x7b',\n",
    "                                    'snowflake-arctic',\n",
    "                                    'mistral-large',\n",
    "                                    'llama3-8b',\n",
    "                                    'llama3-70b',\n",
    "                                    'reka-flash',\n",
    "                                     'mistral-7b',\n",
    "                                     'llama2-70b-chat',\n",
    "                                     'gemma-7b'), key=\"model_name\")\n",
    "\n",
    "    categories = session.table('docs_chunks_table').select('category').distinct().collect()\n",
    "\n",
    "    cat_list = ['ALL']\n",
    "    for cat in categories:\n",
    "        cat_list.append(cat.CATEGORY)\n",
    "            \n",
    "    st.sidebar.selectbox('Select what products you are looking for', cat_list, key = \"category_value\")\n",
    "\n",
    "    st.sidebar.checkbox('Do you want that I remember the chat history?', key=\"use_chat_history\", value = True)\n",
    "\n",
    "    st.sidebar.checkbox('Debug: Click to see summary generated of previous conversation', key=\"debug\", value = True)\n",
    "    st.sidebar.button(\"Start Over\", key=\"clear_conversation\", on_click=init_messages)\n",
    "    st.sidebar.expander(\"Session State\").write(st.session_state)\n",
    "\n",
    "def init_messages():\n",
    "\n",
    "    # Initialize chat history\n",
    "    if st.session_state.clear_conversation or \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "def get_similar_chunks_search_service(query):\n",
    "\n",
    "    if st.session_state.category_value == \"ALL\":\n",
    "        response = svc.search(query, COLUMNS, limit=NUM_CHUNKS)\n",
    "    else: \n",
    "        filter_obj = {\"@eq\": {\"category\": st.session_state.category_value} }\n",
    "        response = svc.search(query, COLUMNS, filter=filter_obj, limit=NUM_CHUNKS)\n",
    "\n",
    "    st.sidebar.json(response.json())\n",
    "    \n",
    "    return response.json()  \n",
    "\n",
    "def get_chat_history():\n",
    "#Get the history from the st.session_stage.messages according to the slide window parameter\n",
    "    \n",
    "    chat_history = []\n",
    "    \n",
    "    start_index = max(0, len(st.session_state.messages) - slide_window)\n",
    "    for i in range (start_index , len(st.session_state.messages) -1):\n",
    "         chat_history.append(st.session_state.messages[i])\n",
    "\n",
    "    return chat_history\n",
    "\n",
    "def summarize_question_with_history(chat_history, question):\n",
    "# To get the right context, use the LLM to first summarize the previous conversation\n",
    "# This will be used to get embeddings and find similar chunks in the docs for context\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Based on the chat history below and the question, generate a query that extend the question\n",
    "        with the chat history provided. The query should be in natual language. \n",
    "        Answer with only the query. Do not add any explanation.\n",
    "        \n",
    "        <chat_history>\n",
    "        {chat_history}\n",
    "        </chat_history>\n",
    "        <question>\n",
    "        {question}\n",
    "        </question>\n",
    "        \"\"\"\n",
    "    \n",
    "    sumary = Complete(st.session_state.model_name, prompt)   \n",
    "\n",
    "    if st.session_state.debug:\n",
    "        st.sidebar.text(\"Summary to be used to find similar chunks in the docs:\")\n",
    "        st.sidebar.caption(sumary)\n",
    "\n",
    "    sumary = sumary.replace(\"'\", \"\")\n",
    "\n",
    "    return sumary\n",
    "\n",
    "def create_prompt (myquestion):\n",
    "\n",
    "    if st.session_state.use_chat_history:\n",
    "        chat_history = get_chat_history()\n",
    "\n",
    "        if chat_history != []: #There is chat_history, so not first question\n",
    "            question_summary = summarize_question_with_history(chat_history, myquestion)\n",
    "            prompt_context =  get_similar_chunks_search_service(question_summary)\n",
    "        else:\n",
    "            prompt_context = get_similar_chunks_search_service(myquestion) #First question when using history\n",
    "    else:\n",
    "        prompt_context = get_similar_chunks_search_service(myquestion)\n",
    "        chat_history = \"\"\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "           You are an expert chat assistance that extracs information from the CONTEXT provided\n",
    "           between <context> and </context> tags.\n",
    "           You offer a chat experience considering the information included in the CHAT HISTORY\n",
    "           provided between <chat_history> and </chat_history> tags..\n",
    "           When ansering the question contained between <question> and </question> tags\n",
    "           be concise and do not hallucinate. \n",
    "           If you donÂ´t have the information just say so.\n",
    "           \n",
    "           Do not mention the CONTEXT used in your answer.\n",
    "           Do not mention the CHAT HISTORY used in your asnwer.\n",
    "\n",
    "           Only anwer the question if you can extract it from the CONTEXT provideed.\n",
    "           \n",
    "           <chat_history>\n",
    "           {chat_history}\n",
    "           </chat_history>\n",
    "           <context>          \n",
    "           {prompt_context}\n",
    "           </context>\n",
    "           <question>  \n",
    "           {myquestion}\n",
    "           </question>\n",
    "           Answer: \n",
    "           \"\"\"\n",
    "    \n",
    "    json_data = json.loads(prompt_context)\n",
    "\n",
    "    relative_paths = set(item['relative_path'] for item in json_data['results'])\n",
    "\n",
    "    return prompt, relative_paths\n",
    "\n",
    "\n",
    "def answer_question(myquestion):\n",
    "\n",
    "    prompt, relative_paths =create_prompt (myquestion)\n",
    "\n",
    "    response = Complete(st.session_state.model_name, prompt)   \n",
    "\n",
    "    return response, relative_paths\n",
    "\n",
    "def main():\n",
    "    \n",
    "    st.title(f\":speech_balloon: Chat Document Assistant with Snowflake Cortex\")\n",
    "    st.write(\"This is the list of documents you already have and that will be used to answer your questions:\")\n",
    "    docs_available = session.sql(\"ls @docs\").collect()\n",
    "    list_docs = []\n",
    "    for doc in docs_available:\n",
    "        list_docs.append(doc[\"name\"])\n",
    "    st.dataframe(list_docs)\n",
    "\n",
    "    config_options()\n",
    "    init_messages()\n",
    "     \n",
    "    # Display chat messages from history on app rerun\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "    \n",
    "    # Accept user input\n",
    "    if question := st.chat_input(\"What do you want to know about your products?\"):\n",
    "        # Add user message to chat history\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": question})\n",
    "        # Display user message in chat message container\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(question)\n",
    "        # Display assistant response in chat message container\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            message_placeholder = st.empty()\n",
    "    \n",
    "            question = question.replace(\"'\",\"\")\n",
    "    \n",
    "            with st.spinner(f\"{st.session_state.model_name} thinking...\"):\n",
    "                response, relative_paths = answer_question(question)            \n",
    "                response = response.replace(\"'\", \"\")\n",
    "                message_placeholder.markdown(response)\n",
    "\n",
    "                if relative_paths != \"None\":\n",
    "                    with st.sidebar.expander(\"Related Documents\"):\n",
    "                        for path in relative_paths:\n",
    "                            cmd2 = f\"select GET_PRESIGNED_URL(@docs, '{path}', 360) as URL_LINK from directory(@docs)\"\n",
    "                            df_url_link = session.sql(cmd2).to_pandas()\n",
    "                            url_link = df_url_link._get_value(0,'URL_LINK')\n",
    "                \n",
    "                            display_url = f\"Doc: [{path}]({url_link})\"\n",
    "                            st.sidebar.markdown(display_url)\n",
    "\n",
    "        \n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8e235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Viewers\n",
      "Like & Subscribe\n"
     ]
    }
   ],
   "source": [
    "def print_messages():\n",
    "    print(\"Hello Viewers\")\n",
    "    print(\"Like & Subscribe\")\n",
    "\n",
    "print_messages()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "lastEditStatus": {
   "authorEmail": "apoorva@imcominghome.io",
   "authorId": "6188994524081",
   "authorName": "APILLUTLA",
   "lastEditTime": 1737239441548,
   "notebookId": "cc4mhv4zj5xqv4qpvr2x",
   "sessionId": "4f614793-374d-4922-8a4e-bc468e8761bd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
